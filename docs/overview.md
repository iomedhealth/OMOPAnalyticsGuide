[]{#ExecutionofaDataMediation.xhtml}

[]{.c0}

[]{.c0}

[]{.c0}

[]{.c0}

[]{.c0}

[]{.c0}

[]{.c0}

[]{.c0}

[]{.c0}

[]{.c0}

[Execution of a Data Mediation]{.c19}

[Overview of the process]{.c35}

[]{.c21}

[]{.c21}

[]{.c21}

[]{.c21}

[]{.c21}

[]{.c21}

[]{.c21}

[]{.c26 .c30}

[]{.c26 .c30}

[]{.c20}

[https://iomed.health]{.c20}

[]{.c12}

------------------------------------------------------------------------

[]{.c0}

[]{.c0}

[]{.c0}

# []{.c16} {#ExecutionofaDataMediation.xhtml_h.i6bhiox914ho .c1 .c9}

[]{.c0}

[]{.c0}

# []{.c16} {#ExecutionofaDataMediation.xhtml_h.r8obpz6b51lx .c1 .c9}

# []{.c16} {#ExecutionofaDataMediation.xhtml_h.oob3372z2d80 .c1 .c9}

# []{.c16} {#ExecutionofaDataMediation.xhtml_h.u6oypgdry9vf .c1 .c9}

[]{.c0}

[]{.c0}

# [Overview]{.c16} {#ExecutionofaDataMediation.xhtml_h.qorxe5hab1oe .c1 .c14}

[Executing a Data Mediation with IOMED follows a structured, multi-phase
approach designed to ensure data integrity, regulatory compliance, and
scientific rigor. The process begins with data preparation, which
includes establishing partnerships with hospitals, securing ethical
approvals, and integrating disparate data sources into a standardized
format. ]{.c0}

[]{.c0}

[Following data preparation, the Data Mediation execution phase focuses
on defining the research objectives, identifying relevant patient
cohorts and the data of interest, and verifying data quality. Advanced
Artificial Intelligence (AI) driven techniques, including Natural
Language Processing (NLP) and Automated Terminology Mapping (ATM),
enhance the accuracy and completeness of extracted information.]{.c0}

[]{.c0}

# [Phases]{.c16} {#ExecutionofaDataMediation.xhtml_h.gjuso6sy50v3 .c1 .c14}

## [Phase 01: ]{.c10} [Data Preparation]{.c17} {#ExecutionofaDataMediation.xhtml_h.mvzndiy5dgbn .c1 .c14}

### [1. Establishing Institutional Partnerships and Ethical Compliance]{.c3} {#ExecutionofaDataMediation.xhtml_h.jhuf8cs50c9 .c1 .c14}

[]{.c0}

[The initiation of a clinical research Data Mediation leveraging IOMED's
infrastructure relies on the establishment of strong institutional
partnerships with Data Holders. This process is not static but rather an
ongoing effort to expand IOMED's federated hospital network. By
continuously integrating new Data Holder, we enhance the depth and
breadth of available clinical data, improving research scalability and
ensuring consistency in data harmonization across multiple healthcare
systems.]{.c0}

[]{.c0}

[
![](assets/images/image10.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[Negotiating these partnerships entails formal contractual agreements
that define the scope of data access, ethical obligations, and
regulatory compliance at both national and international levels.
Compliance with major regulatory frameworks, such as the General Data
Protection Regulation (GDPR) in the European Union and the Health
Insurance Portability and Accountability Act (HIPAA) in the United
States, is fundamental to securing patient confidentiality and
safeguarding sensitive information. These regulations require periodic
compliance reviews, security assessments, and the implementation of
strict data access protocols. To ensure continuous adherence, IOMED
employs encryption mechanisms, real-time monitoring of data access, and
stringent role-based access control. Staff undergo regular training to
stay updated on evolving legal and ethical standards, reinforcing a
culture of compliance across all participating Data Holders.]{.c0}

[]{.c0}

[
![](assets/images/image13.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[IOMED also facilitates the submission of study protocols to
institutional review boards (IRBs) and ethics committees, ensuring
rigorous oversight of data utilization. These bodies play a critical
role in evaluating the ethical implications of the Data Mediation,
ensuring that patient rights and privacy are upheld while also
scrutinizing the research design for scientific validity.]{.c0}

[]{.c0}

[The operationalization of these agreements is underpinned by close
collaboration between IOMED and hospital IT departments. A dedicated
technical framework is deployed to ensure minimal disruption to clinical
workflows while maximizing data extraction efficiency. Furthermore,
dedicated training sessions are provided to healthcare personnel,
equipping them with the knowledge necessary to uphold data governance
principles, follow institutional data-sharing policies, and ensure
alignment with privacy laws. As more Data Holders join IOMED's federated
network, the interoperability of data improves, leading to more robust
and scalable research opportunities.]{.c0}

[]{.c0}

### 2. Data Access and System Integration [ ]{.c36} {#ExecutionofaDataMediation.xhtml_h.g7cepx3xzac3 .c1 .c14}

[Accessing hospital data requires a methodologically rigorous approach
to ensure high-quality, representative databases. Data Holders operate a
complex network of digital systems, each hosting a subset of relevant
patient data. The primary repositories include Electronic Health Records
(EHRs), which document the patient's clinical history; Laboratory
Information Systems (LIS), which store diagnostic test results;
Radiology Information Systems (RIS), which contain imaging data; and
Pharmacy Management Systems (PMS), which track medication prescriptions
and administration records.]{.c0}

[]{.c0}

[Given the decentralized nature of hospital data storage, data
fragmentation is an inherent challenge. To address this, a comprehensive
audit of the available information systems is conducted to assess
completeness, standardization, and compatibility with the OMOP Common
Data Model (CDM), a standardized framework designed to facilitate the
interoperability and analysis of real-world healthcare data across
multiple Data Holders. Integrating disparate datasets into a singular,
analyzable format requires the implementation of sophisticated data
extraction pipelines. These pipelines are designed to retrieve
structured clinical variables such as lab results, diagnosis codes, and
prescription records while also capturing unstructured textual data such
as physician notes and discharge summaries. The integration process is
carefully managed to ensure it does not disrupt routine hospital
operations, thereby maintaining the continuity of patient care.]{.c0}

[
![](assets/images/image3.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[To further bolster security, multi-layered encryption protocols are
established, preventing unauthorized access to patient records. Rigorous
access controls, including role-based authentication, are enforced to
restrict data access solely to authorized personnel. A secure data
transfer mechanism is utilized to prevent breaches, ensuring that data
integrity is maintained throughout the extraction and integration
process.]{.c0}

[]{.c0}

### [3. Patient Data Privacy]{.c3} {#ExecutionofaDataMediation.xhtml_h.bsx781rtempn .c1 .c14}

[Ensuring patient data privacy is of utmost importance when processing
sensitive health information for secondary use. Therefore, the IOMED
platform follows stringent data protection protocols to safeguard
patient privacy and comply with the GDPR, as well as applicable Spanish
data protection regulations.]{.c0}

[]{.c0}

#### 3.1  [Anonymization]{.c7} {#ExecutionofaDataMediation.xhtml_h.c0m2a8dm6j3g .c1 .c14}

[The GDPR defines health data and clarifies that it covers \"data
concerning health" and treats them as a \"special category\" of personal
data which is considered to be sensitive by its nature. In this sense,
IOMED complies with the General Data Protection Regulation (GDPR) of the
EU and the Spanish data protection regulations for the processing of
these data. Moreover, all data that IOMED processes is always
anonymized.]{.c0}

[All hospital data, before being processed for any purpose, is
anonymized by IOMED. The existing unique patient identifiers, such as
the patient number, will be discarded and a random unique identifier
will be assigned to each user. All the personally identifiable
information (PII) such as names and surnames of the patient, as well as
professional career, family or medical data, telephone numbers,
references to places or addresses, email addresses, etc. are discarded
and only the anonymized identifier of the person is available in the
OMOP CDM database. ]{.c0}

[A second anonymization process is performed in the clinical notes using
NLP, where multiple algorithms are used to identify character strings
for names, surnames, telephone numbers, references to places or
addresses, email addresses, etc. and replaced by random content
generate.]{.c0}

[The result is a structured database, which cannot be associated with
unique individuals without additional information and inordinate effort,
time and cost considering currently available technologies.]{.c0}

[Each site will always maintain custody of the data since the software
will be installed on its servers. All the data created is stored within
the hospital and ]{.c10} [no]{.c10} [ data will ever be stored outside
its system. The data will be accessible from the site\'s database and
will be anonymized on its servers.]{.c10} [        ]{.c10 .c24} [\
\
]{.c10 .c22} [ ![Picture
3](assets/images/image14.png){style="width: 566.52px; height: 324.93px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 566.52px; height: 324.93px;"}

[]{.c3}

#### 3.2  [Patient information and informed consent]{.c7} {#ExecutionofaDataMediation.xhtml_h.74ei94s593jr .c1 .c14}

[The AI using machine learning and NPL methodologies to collect data
from EHRs enables a large population to be included in the study, which
hampers obtaining the ICs. However, appropriate data protection measures
in terms of data storage and anonymization of datasets will be applied
(section 7.6.2). As the study data will be entirely anonymized to avoid
subject identification, collected data will not be considered as
personal according to the Code of Best Practices in Data Protection for
Big Data Projects.]{.c0}

[]{.c0}

[According to the Ministerial Order SAS/3470/2009, post-authorization
observational studies that require the subject to be interviewed or
those without a secure dissociation procedure that guarantees that the
information used does not contain personal data, the subject informed
consent will be required. Studies that do not need the patient to be
interviewed but have access to their health and personal data (for
example, medical history) generally require the patient\'s informed
consent, despite the fact that collected information is dissociated.
However, the ethics committee evaluating the study will assess the need
and effort to obtain the informed consent in certain cases (studies with
relevant scientific interest in which obtaining informed consent makes
them unfeasible or with legal authorization for the management/transfer
of personal data).]{.c0}

[]{.c3}

[]{.c0}

### 4. ETL Process: Standardizing Data to OMOP CDM {#ExecutionofaDataMediation.xhtml_h.38asygbsxt8r .c1 .c14}

[]{.c0}

[Once data has been successfully extracted, the next critical step
involves structuring it into a standardized format compatible with OMOP
CDM. The Extract, Transform, and Load (ETL) process is a widely used
methodology in data management that ensures disparate datasets are
refined, harmonized, and systematically mapped to OMOP concepts. ETL
consists of three distinct steps: extraction, which involves retrieving
raw data from multiple hospital systems; transformation, which involves
cleaning, standardizing, and formatting the data to ensure consistency
and interoperability; and loading, which integrates the transformed data
into a structured database for efficient analysis. This process is
crucial for facilitating large-scale, reproducible observational
research, as it enables the seamless integration of real-world clinical
data from different Data Holders.]{.c0}

[]{.c0}

[The extraction phase involves retrieving structured data (e.g., vital
signs, diagnostic tests, and procedural codes) and unstructured data
(e.g., textual physician notes and imaging reports). Data transformation
encompasses a series of cleaning procedures, including handling missing
values, normalizing terminologies, and resolving inconsistencies.
Terminology alignment is crucial at this stage, as different Data
Holders may use institution-specific coding systems that require
translation into OMOP-recognized vocabularies. The final loading phase
involves securely storing the transformed data into an OMOP-compliant
database, ensuring structured access to high-quality clinical
information.]{.c0}

[]{.c0}

[
![](assets/images/image15.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[The automation of the ETL pipeline enhances efficiency, enabling
real-time updates as new patient data becomes available. This ensures
that research findings remain reflective of current clinical trends
while reducing manual intervention, thereby minimizing errors and
inconsistencies in the dataset.]{.c0}

[]{.c0}

### 5. AI-Driven Terminology Mapping for Data Harmonization {#ExecutionofaDataMediation.xhtml_h.ow6qn3p9se9a .c1 .c14}

[]{.c0}

[A major impediment to interoperability in clinical research is the
inconsistency across different Data Holders of medical terminologies,
unique identifiers for diseases, procedures or treatments among others.
Automated Terminology Mapping (ATM), is an AI-driven process that
standardizes disparate medical terminologies by aligning local hospital
codes with globally recognized vocabularies, addressing this challenge
by aligning local hospital coding systems with standardized OMOP
concept_ids. This process facilitates seamless data integration across
multiple sites, ensuring consistency in research outcomes.]{.c0}

[]{.c0}

[
![](assets/images/image1.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[Machine learning algorithms leverage probabilistic models and
deep-learning techniques to establish correspondences between disparate
terminologies. The iterative learning framework embedded in ATM ensures
progressive refinement, allowing for real-time adjustments based on new
mappings. Despite AI-driven automation, expert clinician validation
remains indispensable, serving as a safeguard to verify mappings and
address discrepancies. A hybrid model integrating AI automation with
rule-based heuristics guarantees a high level of precision.]{.c0}

[]{.c0}

[A comprehensive audit trail of mapping decisions is maintained to
enhance transparency and facilitate retrospective evaluations. These
audit trails are securely logged and accessible to authorized personnel
for regulatory compliance reviews and quality assurance assessments.
They enable investigators to trace data transformations, verify
mappings, and resolve discrepancies efficiently. Additionally, audit
trails play a critical role in external regulatory audits and
retrospective data evaluations, ensuring that study methodologies remain
reproducible and verifiable. This is particularly valuable when refining
terminology mappings based on evolving medical standards or novel
research findings.]{.c0}

[]{.c0}

### 6. NLP-Enabled Extraction of Clinical Narratives {#ExecutionofaDataMediation.xhtml_h.m3hrnzu57jhq .c1 .c14}

[]{.c0}

[A significant portion of valuable clinical data is embedded within
unstructured text, such as physician notes, radiology reports, discharge
summaries, and pathology narratives. Unlike structured electronic health
records (EHRs) that capture predefined clinical variables, unstructured
narratives often contain nuanced insights about a patient's condition,
treatment progress, and physician assessments. Extracting and
structuring this data is critical for comprehensive clinical research
and real-world evidence generation.]{.c0}

[]{.c0}

[To achieve this, IOMED employs advanced Natural Language Processing
(NLP) techniques designed to interpret and extract clinically relevant
information from textual data sources. The NLP pipeline incorporates
Named Entity Recognition (NER), which identifies key medical terms,
including diagnoses, medications, procedures, and symptoms.
Additionally, contextual embeddings and deep learning models enhance the
recognition of complex relationships within the text, allowing for the
differentiation of disease mentions, temporal associations, and
treatment outcomes.]{.c0}

[]{.c0}

[
![](assets/images/image7.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[Once extracted, these clinical entities are mapped to OMOP concept_ids,
ensuring compatibility with standardized medical terminologies and
facilitating seamless integration into structured databases. The
accuracy and reliability of NLP-extracted data are continuously assessed
through rigorous validation processes. Physician oversight plays a
crucial role in reviewing the extracted information, helping refine
model accuracy and reducing false positives or misinterpretations.
Moreover, precision-recall metrics are systematically evaluated to
improve performance over time.]{.c0}

[]{.c0}

[Beyond entity recognition, NLP models also facilitate further  analysis
such as negation detection, identifying whether a specific condition or
symptom was affirmed, referred to the patient (family history), or
discussed as a possibility or conditionally. This capability enhances
the specificity of the extracted insights, ensuring that clinical data
is accurately categorized. ]{.c0}

[]{.c0}

[]{.c0}

[]{.c0}

[]{.c0}

### 7. Quality Assurance {#ExecutionofaDataMediation.xhtml_h.fd4clb6lzu0k .c1 .c14}

[]{.c0}

[Ensuring the integrity and reliability of extracted data is paramount.
A comprehensive Quality Assurance (QA) framework is implemented to
validate compliance with OMOP CDM standards. Remote Source Data
Verification (rSDV) is performed by medical experts, who cross-check
AI-generated data with original medical records. Statistical assessments
evaluate dataset completeness, logical consistency, and clinical
plausibility. Any discrepancies identified during validation are fed
into an iterative optimization loop, enhancing AI model performance over
time.]{.c0}

[]{.c0}

[
![](assets/images/image2.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[A critical component of the QA framework is false negative detection,
which focuses on identifying instances where clinically relevant
entities were not captured by the system. False negatives pose a
significant challenge in Named Entity Recognition (NER) and Named Entity
Linking (NEL) systems, as they represent missed medical terms that are
essential for research accuracy.]{.c0}

[]{.c0}

[To address this, IOMED employs an advanced framework that utilizes text
similarity search techniques to rank clinical documents based on their
probability of containing false negatives. The system starts by
identifying medical records where the NER/NEL model has successfully
recognized a target medical entity. These identified records serve as a
reference to locate similar documents that lack the detected entity,
despite containing semantically comparable information. By leveraging
shared medical concepts and contextual embeddings, the model efficiently
surfaces documents that are likely to contain undetected entities.]{.c0}

[]{.c0}

[
![](assets/images/image5.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[Human annotators then review the high-probability false negative cases,
verifying whether the target concept is indeed present but was not
initially extracted. This process allows for continuous refinement of
the AI model, systematically reducing the rate of false negatives over
successive iterations. Furthermore, performance evaluation metrics,
including recall, precision, and F1-score, are continuously monitored to
quantify improvements and adjust detection thresholds accordingly.]{.c0}

[]{.c0}

[By incorporating automated false negative detection into the QA
pipeline, IOMED enhances the completeness and accuracy of its datasets,
ensuring that research findings are robust and reflective of real-world
clinical data. ]{.c0}

[]{.c0}

In addition to the rSDV process focused on the AI-generated data, the QA
framework is complemented by a general Validation procedure designed to
assess [ the quality of a Data Order by measuring the accuracy of each
of its datapoints. Validation is achieved through the definition,
implementation, execution and evaluation of a set of quality checks.
]{.c0}

[]{.c0}

[These checks are collaboratively defined by the Quality and Clinical
teams to assess the data's conformance, completeness, and plausibility.
The implementation and execution of the defined checks is done using the
Quality Check System (QCS), which enables the parameterization and
automated execution of all assigned checks to a Data Order for each
iteration. The QCS records the outcome of each check (e.g., pass or
fail), providing a means to monitor and evaluate data quality over
time.]{.c0}

Following execution, a Quality Assurance specialist reviews the results
to determine whether a quality incident should be raised. A quality
incident refers to an unexpected or undesired event occurring within the
system or related to the product. When identified, incidents are logged
in the Incident Management Platform (IMP), which also tracks their
diagnosis and any corrective or preventive actions taken.

[This iterative validation process not only improves the reliability of
extracted medical concepts but also strengthens the overall credibility
of clinical studies conducted using IOMED\'s platform.]{.c0}

[]{.c0}

[]{.c0}

------------------------------------------------------------------------

## []{.c10 .c31} {#ExecutionofaDataMediation.xhtml_h.18hvu1jqjiv8 .c1 .c14 .c33}

## [Phase 02: ]{.c10} Data Mediation Execution {#ExecutionofaDataMediation.xhtml_h.kswqterpfznd .c1 .c14}

### []{.c3} {#ExecutionofaDataMediation.xhtml_h.pzgdii3h8jf5 .c1 .c14 .c27}

[Executing a Data Mediation using IOMED\'s infrastructure is a
meticulous and multi-faceted process that transforms raw clinical data
into scientifically rigorous findings. This phase encompasses protocol
development, data selection, cohort identification, and rigorous
validation mechanisms to ensure the reliability of results. AI-powered
methodologies, including Natural Language Processing (NLP) and Automated
Terminology Mapping (ATM), enhance the precision and completeness of
extracted information. Each step is carefully designed to align with
international research standards and regulatory requirements, ensuring
that results are reproducible and clinically meaningful. ]{.c0}

[]{.c0}

[
![](assets/images/image8.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

### [1. Development of Data Mediation Protocols]{.c3} {#ExecutionofaDataMediation.xhtml_h.xasobq2x7qda .c1 .c14}

[]{.c0}

[A rigorously structured Data Mediation protocol is the cornerstone of a
scientifically valid research project. The protocol serves as a
blueprint, outlining the objectives, methodology, analytical approach,
and ethical considerations. The first step in protocol development
involves defining the research question and establishing the hypothesis
that the study seeks to address.]{.c0}

[]{.c0}

[The protocol details inclusion and exclusion criteria for patient
selection, ensuring a clearly defined cohort. Additionally, it specifies
the data sources to be used, including structured electronic health
records (EHRs) and unstructured clinical narratives. A key component of
the protocol is the statistical analysis plan, which defines the
methodologies for hypothesis testing, confounder adjustments, and risk
stratification. This helps to delineate the dataset necessary for the
Data Mediation.]{.c0}

[]{.c0}

[Before data extraction can proceed, the protocol undergoes multiple
levels of review, including Institutional Review Boards (IRBs) by the
Data Holders and Ethics Committees (EC). These reviews play a critical
role in ensuring that research methodologies align with ethical and
regulatory standards while safeguarding patient privacy. However, they
can significantly impact Data Mediation timelines, as approval processes
often involve multiple iterations of document revisions, responses to
ethical concerns, and additional data privacy assessments. Common
challenges in obtaining approvals include varying regional regulatory
requirements, institutional hesitancy regarding data sharing, and the
necessity of providing extensive documentation on AI-driven data
processing methodologies. Addressing these challenges proactively
through clear communication with review boards, specific training in
each Data Holder and robust compliance frameworks can help mitigate
delays and streamline the approval process. These reviews ensure
compliance with legal, ethical, and scientific standards while
safeguarding patient privacy. Finally, the Data Mediation protocol is
registered with appropriate regulatory bodies where applicable.]{.c0}

[]{.c0}

### [2. Defining of the data of interest for the Cohorts]{.c3} {#ExecutionofaDataMediation.xhtml_h.hqq0q1mfwxh9 .c1 .c14}

[]{.c0}

[A pivotal step in Data Mediation execution is defining the specific
clinical variables and concepts that will be used to construct research
cohorts and the delivery format. Concept sets are collections of
standardized terms that correspond to medical conditions, procedures,
laboratory results, and medications, all mapped to the OMOP Common Data
Model (CDM).]{.c0}

[]{.c0}

[To ensure robustness, concept sets undergo an extensive curation
process, involving domain experts and clinical researchers who review
and refine selections. The goal is to capture relevant patient
attributes with high specificity and sensitivity while ensuring
cross-Data Holder applicability. Advanced AI-assisted tools support this
process by identifying synonyms, hierarchical relationships, and
alternative coding systems used in various hospital environments.]{.c0}

[]{.c0}

[
![](assets/images/image4.png){style="width: 808.00px; height: 454.78px; margin-left: -88.46px; margin-top: -105.48px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[Once finalized, the concept sets serve as the basis for extracting
patient cohorts, ensuring uniform data representation across multiple
participating Data Holders. This standardization facilitates comparative
analyses, meta-analyses, and large-scale observational studies.
Depending on the Data Mediation, validation by Key Opinion Leaders
(KOLs) can ensure scientific rigor and clinical relevance.]{.c0}

[]{.c0}

[
![](assets/images/image16.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[Table: ]{.c4} [A description of the deliverable types available in the
platform.]{.c10 .c11}

[]{.c0}

### [3. Patient Cohort Identification and Validation]{.c3} {#ExecutionofaDataMediation.xhtml_h.v9aenqekbox7 .c1 .c14}

[]{.c0}

[Identifying patient cohorts is a critical phase, requiring precise
query execution within the OMOP CDM framework. Predefined inclusion and
exclusion criteria are translated into queries that extract relevant
patient data from harmonized hospital databases.]{.c0}

[]{.c0}

[After cohort extraction, a comprehensive validation process begins.
Algorithms perform initial checks, detecting inconsistencies or
anomalies in selected patients. Subsequently, clinician-led adjudication
is conducted to verify that the retrieved patients meet the intended
Data Mediation criteria. This validation phase is crucial for
eliminating false positives and ensuring the fidelity of the
cohort.]{.c0}

[]{.c0}

[Beyond individual patient validation, statistical techniques are
employed to assess overall cohort representativeness. Comparative
analyses are conducted against known epidemiological benchmarks to
verify that the Data Mediation population reflects the real-world
clinical landscape. If discrepancies arise, iterative refinements are
made to the cohort selection algorithm to optimize sensitivity and
specificity.]{.c0}

[]{.c0}

### [4. Iterative AI Model Refinement and Performance Optimization]{.c3} {#ExecutionofaDataMediation.xhtml_h.a1nl62n1jit .c1 .c14}

[]{.c0}

[Given the dynamic nature of clinical data and evolving medical
terminologies, AI models require continuous optimization to maintain
high levels of accuracy. During Data Mediation execution, iterative AI
model retraining is conducted using newly validated datasets, ensuring
that algorithms remain robust and reflective of contemporary clinical
practices.]{.c0}

[]{.c0}

[AI model retraining follows a structured pipeline: first, misclassified
or uncertain data points are flagged for manual review by domain
experts. These retraining cycles occur at regular intervals, typically
aligned with major dataset updates or periodic performance evaluations.
The benchmarks for determining model improvement include precision,
recall, and F1-score metrics, which are continuously assessed against
manually verified gold-standard datasets. Additionally, bias detection
and mitigation assessments ensure that retraining enhances model
fairness across different demographic and clinical subgroups. Once
corrections are made, these verified datasets are fed back into the AI
models to refine their classification accuracy. Additionally, bias
assessments are conducted to ensure fairness across diverse patient
populations, preventing systematic discrepancies based on demographic or
socioeconomic factors.]{.c0}

[]{.c0}

[
![](assets/images/image9.png){style="width: 601.70px; height: 338.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 338.67px;"}

[]{.c0}

[Regular performance monitoring is implemented, with precision-recall
metrics used to evaluate AI model reliability. The goal of continuous
retraining is to iteratively improve the accuracy and generalizability
of automated data extraction processes, enhancing the quality of
downstream research outcomes. This retraining and validation process is
independently performed at every site within the IOMED federated
network, ensuring that any AI-driven data extraction is accurate and
reliable across all participating Data Holders. By conducting
site-specific evaluations, discrepancies due to Data Holders differences
in documentation and coding practices can be identified and corrected,
strengthening the overall robustness of extracted datasets.]{.c0}

[]{.c0}

### [5. Delivery of the Data Mediation and External Quality Assurance]{.c3} {#ExecutionofaDataMediation.xhtml_h.deje6c8n0hf5 .c1 .c14}

[]{.c0}

[Once validated, anonymized datasets are prepared for sharing with
research collaborators, regulatory agencies, and scientific communities.
Data sharing adheres to FAIR (Findable, Accessible, Interoperable,
Reusable) principles, facilitating broader scientific engagement and
secondary analyses by independent research groups.]{.c0}

[]{.c0}

[In parallel, structured quality assurance reports are generated,
detailing the Data Mediation's methodology, cohort selection criteria,
data transformation processes, and AI validation techniques. These
reports serve as comprehensive documentation of the research workflow,
enhancing credibility and enabling future methodological
refinements.]{.c0}

[]{.c0}

[The final phase involves the data delivery and external peer review by
the partner performing the analysis on the data. External peers, often
Contract Research Organizations (CROs), play a crucial role in
maintaining data quality by independently reviewing and validating
extracted datasets. Within the IOMED Data Space Platform, these external
partners can formally report data quality incidents if discrepancies,
inconsistencies, or anomalies are detected during their analyses.]{.c0}

[]{.c0}

[Each reported incident is logged into the Data Space Platform, where it
undergoes structured investigation and resolution workflows. These
processes adhere strictly to the ISO 9001-certified Quality Management
System (QMS) established by IOMED, ensuring that all corrective actions
follow standardized procedures, are traceable, and contribute to
continuous quality improvement. Internal data validation teams
systematically assess and prioritize reported issues, addressing them
through iterative AI model refinements, clinician-led adjudications, or
enhancements in terminology mapping.]{.c0}

[]{.c0}

Beyond external reviews, internal audits are also conducted to
preemptively identify potential quality issues before data reaches
external stakeholders. This dual-layered approach, combining internal
validation with external quality assurance mechanisms, reinforces [ the
reliability and reproducibility of studies executed within IOMED's
federated research network. By integrating ISO 9001-aligned quality
management protocols, IOMED ensures that every dataset delivered meets
the highest standards of accuracy and scientific rigor.]{.c0}

[]{.c0}

# [Conclusion]{.c16} {#ExecutionofaDataMediation.xhtml_h.oqiq2hwfdopi .c1 .c14}

[The execution of a Data Mediation using IOMED's infrastructure
represents a highly structured and rigorous process, combining advanced
AI-driven methodologies with robust data governance and quality
assurance frameworks. By establishing strong institutional partnerships,
ensuring compliance with regulatory standards, and employing
sophisticated data integration techniques, IOMED enhances the
accessibility and interoperability of real-world healthcare data.]{.c0}

[The Data Mediation execution phase further refines this process by
leveraging Natural Language Processing (NLP) and Automated Terminology
Mapping (ATM) to extract and standardize clinical concepts, ensuring
that patient cohorts are precisely identified and validated. Continuous
AI model retraining, coupled with independent site-specific evaluations,
ensures that extracted data maintains the highest levels of accuracy and
reliability across diverse healthcare settings.]{.c0}

[Furthermore, IOMED's ISO 9001-certified Quality Management System (QMS)
provides a structured framework for both internal and external data
quality validation. The ability for external peers, such as Contract
Research Organizations (CROs), to report and resolve data quality
incidents within the Data Space Platform ensures that studies maintain
scientific rigor and reproducibility. This dual-layered validation
approach strengthens the integrity of research findings and contributes
to the broader adoption of real-world data in clinical decision-making
and policy development.]{.c0}

[Through this comprehensive, multi-phase approach, IOMED facilitates
high-quality, large-scale clinical research while continuously improving
data accuracy and standardization. The integration of cutting-edge AI
tools with stringent quality control measures underscores IOMED's
commitment to advancing evidence-based medicine, fostering innovation in
healthcare research, and ultimately improving patient outcomes. ]{.c0}

[]{.c0}

  [ ![](assets/images/image6.png){style="width: 131.11px; height: 47.85px; margin-left: -0.31px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"} ]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 130.50px; height: 47.85px;"}   
  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --

------------------------------------------------------------------------

[
![](assets/images/image12.jpg){style="width: 1051.00px; height: 1326.36px; margin-left: -196.00px; margin-top: -23.48px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 808.00px; height: 1302.88px;"}
[
![](assets/images/image11.png){style="width: 248.50px; height: 90.74px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}
]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 248.50px; height: 90.74px;"}
